# Toxic Text Classifier

## Sections

- [About](#about)
- [Demo Site](#demo)

## About <a id="about"></a>

The Toxic Text Classifier is a tool designed to analyze and categorize text into various toxicity levels. This project utilizes a fine-tuned BERT model for text classification, leveraging TensorFlow and Hugging Face Transformers for NLP capabilities.


| -------- | -------- | -------- | -------- | -------- | -------- |
| Toxic | Severe Toxic | Obscene | Threat | Insult | Identity Hate |

### <ins> Available Models </ins>

The site includes various pre-trained models with different levels of training and weighting:

- **Toxicity - 1 Epoch**

- **Toxicity - 8 Epochs**

- **[Toxicity - Weighted](https://huggingface.co/RobCaamano/toxicity_weighted)**

- **[DistilBERT Base Uncased (SST-2)](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)**

## Demo Site <a id="demo"></a>

[link](https://sites.google.com/view/detecting-toxicity-in-text/home)
